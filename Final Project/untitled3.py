# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucxqDfH1kYpBR29eVmYshZcIRif69-0Q
"""

import pandas as pd

# Load the Excel file into a Pandas DataFrame
excel_file = "CoralBleaching-2.xlsx"
df = pd.read_excel(excel_file)

# Display the first few rows of the DataFrame to understand its structure
print("First few rows of the DataFrame:")
print(df.head())

# Get information about the DataFrame
print("\nInformation about the DataFrame:")
print(df.info())

# Get summary statistics for numerical columns
print("\nSummary statistics for numerical columns:")
print(df.describe())

import pandas as pd

# Load the Excel file into a Pandas DataFrame
excel_file = "CoralBleaching-2.xlsx"
df = pd.read_excel(excel_file)

# Drop rows with missing location information
df.dropna(subset=['COUNTRY'], inplace=True)

# Group by country and calculate total events and average severity
hotspots = df.groupby('COUNTRY').agg({
    'ID': 'count',  # Total number of events
    'SEVERITY_CODE': 'mean'  # Average severity
}).rename(columns={'ID': 'Total Events', 'SEVERITY_CODE': 'Avg Severity'}).reset_index()

# Sort hotspots by total events in descending order
hotspots = hotspots.sort_values(by='Total Events', ascending=False)

# Display top 10 hotspots
print("Top 10 Coral Bleaching Hotspots:")
print(hotspots.head(10))

import matplotlib.pyplot as plt

# Group by year and calculate total events and average severity
temporal_analysis = df.groupby('YEAR').agg({
    'ID': 'count',  # Total number of events
    'SEVERITY_CODE': 'mean'  # Average severity
}).rename(columns={'ID': 'Total Events', 'SEVERITY_CODE': 'Avg Severity'}).reset_index()

# Plot temporal analysis
plt.figure(figsize=(10, 6))
plt.plot(temporal_analysis['YEAR'], temporal_analysis['Total Events'], marker='o', color='b', label='Total Events')
plt.plot(temporal_analysis['YEAR'], temporal_analysis['Avg Severity'], marker='s', color='r', label='Avg Severity')
plt.xlabel('Year')
plt.ylabel('Count / Severity')
plt.title('Temporal Analysis of Coral Bleaching Events')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Extract numeric values from water temperature range
df['WATER_TEMP_MIN'] = df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)')
df['WATER_TEMP_MAX'] = df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)', expand=False)

# Convert extracted values to numeric
df['WATER_TEMP_MIN'] = pd.to_numeric(df['WATER_TEMP_MIN'], errors='coerce')
df['WATER_TEMP_MAX'] = pd.to_numeric(df['WATER_TEMP_MAX'], errors='coerce')

# Calculate average temperature
df['WATER_TEMP_AVG'] = (df['WATER_TEMP_MIN'] + df['WATER_TEMP_MAX']) / 2

# Plot relationship between water temperature and average severity
plt.figure(figsize=(10, 6))
plt.scatter(df['WATER_TEMP_AVG'], df['SEVERITY_CODE'], color='b', alpha=0.5)
plt.xlabel('Water Temperature (°C)')
plt.ylabel('Average Severity')
plt.title('Relationship between Water Temperature and Coral Bleaching Severity')
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.impute import SimpleImputer

# Impute missing values in the feature matrix (X)
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Train a linear regression model on the imputed data
model = LinearRegression()
model.fit(X_train_imputed, y_train)

# Make predictions on the testing set
y_pred = model.predict(X_test_imputed)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Predict severity for a new water temperature value
new_temperature = [[30]]  # Example: predict severity for a water temperature of 30°C
new_temperature_imputed = imputer.transform(new_temperature)
predicted_severity = model.predict(new_temperature_imputed)
print("Predicted Severity:", predicted_severity)

# Find the maximum severity value and its index
max_severity_index = df['SEVERITY_CODE'].idxmax()
max_severity = df.loc[max_severity_index, 'SEVERITY_CODE']

# Get the latitude and longitude corresponding to the maximum severity
worst_lat = df.loc[max_severity_index, 'LAT']
worst_lon = df.loc[max_severity_index, 'LON']

print("Latitude of the worst severity:", worst_lat)
print("Longitude of the worst severity:", worst_lon)
print("Maximum severity:", max_severity)

# Find records with the highest severity
worst_records = df[df['SEVERITY_CODE'] == df['SEVERITY_CODE'].max()]

# Extract latitude and longitude values for the worst records
worst_latitudes = worst_records['LAT'].values
worst_longitudes = worst_records['LON'].values

# Print the worst severity and corresponding coordinates
print("Worst Severity:", worst_records['SEVERITY_CODE'].values[0])
print("Latitude:", worst_latitudes)
print("Longitude:", worst_longitudes)

import folium

# Create a folium map centered at the worst severity location
map_center = [worst_lat, worst_lon]
mymap = folium.Map(location=map_center, zoom_start=10)

# Add a marker at the worst severity location
folium.Marker(location=[worst_lat, worst_lon], popup='Worst Severity Location').add_to(mymap)

# Display the map
mymap.save('worst_severity_map.html')

# Filter the dataset to include only rows with the highest severity level
highest_severity_df = df[df['SEVERITY_CODE'] == max_severity].copy()

# Convert water temperature to numerical values
highest_severity_df['WATER_TEMP_MIN'] = highest_severity_df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)')
highest_severity_df['WATER_TEMP_MAX'] = highest_severity_df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)', expand=False)

# Convert extracted values to numeric
highest_severity_df['WATER_TEMP_MIN'] = pd.to_numeric(highest_severity_df['WATER_TEMP_MIN'], errors='coerce')
highest_severity_df['WATER_TEMP_MAX'] = pd.to_numeric(highest_severity_df['WATER_TEMP_MAX'], errors='coerce')

# Calculate average temperature
highest_severity_df['WATER_TEMP_AVG'] = (highest_severity_df['WATER_TEMP_MIN'] + highest_severity_df['WATER_TEMP_MAX']) / 2

# Calculate the average temperature for locations with the highest severity level
average_temp_highest_severity = highest_severity_df['WATER_TEMP_AVG'].mean()

print("Average water temperature for locations with the highest severity level:", average_temp_highest_severity)

# Convert water temperature to numerical values
df['WATER_TEMP_MIN'] = df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)')
df['WATER_TEMP_MAX'] = df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)', expand=False)

# Convert extracted values to numeric
df['WATER_TEMP_MIN'] = pd.to_numeric(df['WATER_TEMP_MIN'], errors='coerce')
df['WATER_TEMP_MAX'] = pd.to_numeric(df['WATER_TEMP_MAX'], errors='coerce')

# Calculate average temperature
df['WATER_TEMP_AVG'] = (df['WATER_TEMP_MIN'] + df['WATER_TEMP_MAX']) / 2

# Group by severity level and calculate average temperature for each group
average_temp_by_severity = df.groupby('SEVERITY_CODE')['WATER_TEMP_AVG'].mean()

print("Average water temperature for each severity level:")
print(average_temp_by_severity)

# Define the severity levels
severity_levels = sorted(df['SEVERITY_CODE'].unique())

# Create an empty dictionary to store average temperatures for each severity level
average_temperatures = {}

# Iterate over each severity level
for severity_level in severity_levels:
    # Filter the dataset to include only rows with the current severity level
    filtered_df = df[df['SEVERITY_CODE'] == severity_level].copy()

    # Convert water temperature to numerical values
    filtered_df['WATER_TEMP_MIN'] = filtered_df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)')
    filtered_df['WATER_TEMP_MAX'] = filtered_df['WATER_TEMPERATURE'].str.extract(r'(\d+.\d+)', expand=False)
    filtered_df['WATER_TEMP_MIN'] = pd.to_numeric(filtered_df['WATER_TEMP_MIN'], errors='coerce')
    filtered_df['WATER_TEMP_MAX'] = pd.to_numeric(filtered_df['WATER_TEMP_MAX'], errors='coerce')

    # Calculate average temperature
    filtered_df['WATER_TEMP_AVG'] = (filtered_df['WATER_TEMP_MIN'] + filtered_df['WATER_TEMP_MAX']) / 2

    # Calculate the average temperature for the current severity level
    average_temperature = filtered_df['WATER_TEMP_AVG'].mean()

    # Store the average temperature in the dictionary
    average_temperatures[severity_level] = average_temperature

# Print average temperatures for each severity level
for severity_level, average_temp in average_temperatures.items():
    print(f"Average water temperature for severity level {severity_level}: {average_temp}")

# Iterate over each severity level
for severity_level in severity_levels:
    # Filter the dataset to include only rows with the current severity level
    filtered_df = df[df['SEVERITY_CODE'] == severity_level].copy()

    # Display the data for the current severity level
    print(f"Data for severity level {severity_level}:")
    print(filtered_df[['WATER_TEMPERATURE', 'WATER_TEMP_MIN', 'WATER_TEMP_MAX', 'WATER_TEMP_AVG']].head())

# Define grid or binning strategy
lat_bins = np.linspace(df['LAT'].min(), df['LAT'].max(), num=10)
lon_bins = np.linspace(df['LON'].min(), df['LON'].max(), num=10)

# Bin latitude and longitude coordinates
df['LAT_BIN'] = pd.cut(df['LAT'], bins=lat_bins)
df['LON_BIN'] = pd.cut(df['LON'], bins=lon_bins)

# Group by latitude and longitude bins and calculate average severity level
avg_severity_by_region = df.groupby(['LAT_BIN', 'LON_BIN'])['SEVERITY_CODE'].mean()

print("Average severity level for each region:")
print(avg_severity_by_region)

import numpy as np  # Import NumPy library

# Define grid or binning strategy
lat_bins = np.linspace(df['LAT'].min(), df['LAT'].max(), num=10)
lon_bins = np.linspace(df['LON'].min(), df['LON'].max(), num=10)

# Bin latitude and longitude coordinates
df['LAT_BIN'] = pd.cut(df['LAT'], bins=lat_bins)
df['LON_BIN'] = pd.cut(df['LON'], bins=lon_bins)

# Group by latitude and longitude bins and calculate average severity level
avg_severity_by_region = df.groupby(['LAT_BIN', 'LON_BIN'])['SEVERITY_CODE'].mean()

print("Average severity level for each region:")
print(avg_severity_by_region)